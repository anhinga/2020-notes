### Research notes

---

### January 2020

Title:

_Using streams of probabilistic samples in neural machines_

---

Abstract:
  * We describe a class of neural machines capable of processing streams of probabilistic samples. The samples themselves can be, e.g., compound objects of discrete nature if so desired, and the neural machines in question don't need to embed those samples into vector spaces, but can process them ``as is". 
  * While it is customary to process one stream element per one cycle of a neural machine, the mechanism we describe allows for temporal sparsity, that is, it allows to provide a stream element only occasionally, if so desired. We describe mechanisms allowing to combine streams of probabilistic samples with positive coefficients, with arbitrary real coefficients, and with complex coefficients.
  
---

### March 2020

Title:

_Synergy between AI-generating algorithms and dataflow matrix machines_

---

Abstract:
  * _AI-generating algorithms_ is an alternate paradigm for producing general artificial intelligence
introduced by Jeff Clune in 2019. Its idea is to create an algorithm which itself automatically learns how
to produce general AI. The approach is structured into three pillars: 1) meta-learning AI architectures, 2) 
meta-learning the learning algorithms, and 3) generating effective learning environments.
  * _Dataflow matrix machines_ form a novel class of programmable neural machines bridging the gap
between programs and recurrent neural networks. This class of neural machines seems to be suitable
for general purpose programming, allows to conveniently express powerful self-modification facilities,
and seems to be naturally tailored for the tasks of synthesizing modular neural architectures.
  * In this essay, I argue that there is deep synergy between AI-generating algorithms (AI-GAs) and
dataflow matrix machines (DMMs). The particular focus of the present essay is an argument that
DMMs are an extremely natural fit for the first two pillars of AI-GAs.
  * I also briefly overview the current state of DMM research, and consider further possibilities of potential
fruitful interaction between AI-GAs and DMMs.
